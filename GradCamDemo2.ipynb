{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893e1716-e0b6-4541-8211-5b2ebac86327",
   "metadata": {},
   "source": [
    "# GradCAM Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064140b5-9ea5-4bb9-9b8a-0d85f92d4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\__init__.py:651: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ..\\c10\\cuda\\CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from backbones.mobilenetv3small import MobileNetV3Small\n",
    "from backbones.resnet50 import ResNet50\n",
    "from backbones.resnet34 import ResNet34\n",
    "from backbones.resnet18 import ResNet18\n",
    "from backbones.swinv2t import SwinV2T\n",
    "from backbones.swint import SwinT\n",
    "from backbones.vitb16 import ViTB16\n",
    "from backbones.detr import DETR\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d44e2a6-4898-483f-933a-980a068ad701",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_types = {\n",
    "    \"grad\": GradCAM,\n",
    "    \"hires\": HiResCAM,\n",
    "    \"score\": ScoreCAM,\n",
    "    \"gradpp\": GradCAMPlusPlus,\n",
    "    \"abl\": AblationCAM,\n",
    "    \"xgrad\": XGradCAM,\n",
    "    \"eigen\": EigenCAM,\n",
    "    \"full\": FullGrad\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78264267-bb46-430c-affd-40f108df41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_with_heatmap(original_image_path, output_dir, filename_suffix, visualization, heatmap):\n",
    "    dirname, filename = os.path.split(original_image_path)\n",
    "    filename, fileext = os.path.splitext(filename)\n",
    "    cv2.imwrite(f\"{output_dir}/{filename}_{filename_suffix}.jpg\", cv2.cvtColor(visualization, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "def load_images(glob_path: str):\n",
    "    image_paths = glob.glob(glob_path)\n",
    "    paths = []\n",
    "    input_images = []\n",
    "    for path in image_paths:\n",
    "        paths.append(path)\n",
    "        input_images.append(Image.open(path))\n",
    "    return paths, input_images\n",
    "\n",
    "def load_input_batch(glob_path: str, preprocess):\n",
    "    paths, input_images = load_images(glob_path)\n",
    "    input_tensors = []\n",
    "    for img in input_images:\n",
    "        input_tensors.append(preprocess(img).unsqueeze(0))\n",
    "\n",
    "    input_batch = torch.cat(input_tensors)\n",
    "    return paths, input_batch\n",
    "\n",
    "def create_cam_images(glob_path: str, backbone, output_path: str, cam_name = \"grad\", cam_layer_index: int = 0, image_size=224, reshape_transform = None):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    normalize = transforms.Compose([\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    paths, input_batch = load_input_batch(glob_path, preprocess)\n",
    "    model = backbone\n",
    "    target_layers = [backbone.gradcam_layers[cam_layer_index]]\n",
    "    cam_type = cam_types[cam_name]\n",
    "    heatmaps = []\n",
    "    visualizations = []\n",
    "\n",
    "    # Construct the CAM object once, and then re-use it on many images:\n",
    "    with cam_type(model=model, target_layers=target_layers, reshape_transform=reshape_transform) as cam:\n",
    "        # We have to specify the target we want to generate\n",
    "        # the Class Activation Maps for.\n",
    "        # If targets is None, the highest scoring category\n",
    "        # will be used for every image in the batch.\n",
    "        # Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
    "        # That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
    "\n",
    "        # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
    "        grayscale_cam = cam(input_tensor=normalize(input_batch), targets=targets)\n",
    "\n",
    "        for i in range(input_batch.shape[0]):\n",
    "            heatmap = grayscale_cam[i, :]\n",
    "            heatmaps.append(heatmap)\n",
    "            visualizations.append(show_cam_on_image(input_batch[i].detach().cpu().permute(1,2,0).numpy(), heatmap, use_rgb=True))\n",
    "        for i in range(len(visualizations)):\n",
    "            save_image_with_heatmap(paths[i], output_path, f\"{cam_name}_layer{cam_layer_index}_{backbone.name}\", visualizations[i], heatmaps[i])\n",
    "            \n",
    "def reshape_transform_swin_transformer(tensor, height=7, width=7):\n",
    "    result = tensor.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "def reshape_transform_vit(tensor, height=14, width=14):\n",
    "    result = tensor[:, 1 :  , :].reshape(tensor.size(0),\n",
    "        height, width, tensor.size(2))\n",
    "\n",
    "    # Bring the channels to the first dimension,\n",
    "    # like in CNNs.\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5297bd1d-7c0a-41a6-9e7c-f413dffabe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\tilof/.cache\\torch\\hub\\facebookresearch_detr_main\n",
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tilof\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIONS torch.Size([92, 256])\n"
     ]
    }
   ],
   "source": [
    "#backbone = DETR()\n",
    "backbone = DETR(filepath=\"C:\\\\Users\\\\tilof\\\\PycharmProjects\\\\DeepLearningProjects\\\\DETR\\\\results\\\\spine\\detr_r50\\\\checkpoint.pth\")\n",
    "classifier_output_target = -1\n",
    "if classifier_output_target > -1:\n",
    "    targets = [ClassifierOutputTarget(2)]\n",
    "else:\n",
    "    targets=None\n",
    "    \n",
    "for i, _ in enumerate(backbone.gradcam_layers):\n",
    "    create_cam_images(\n",
    "        \"images/dog/*.png\",\n",
    "        backbone,\n",
    "        \"images/dog/gradcam\",\n",
    "        cam_name=\"grad\",\n",
    "        image_size=512,\n",
    "        cam_layer_index=i,\n",
    "        reshape_transform=backbone.gradcam_reshape_transform\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef89252-2b6c-43ab-b995-7c85dcf385bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
