{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fae703-33f7-4c16-a096-753e23dabcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from backbones.resnet18 import ResNet18\n",
    "from backbones.resnet50 import ResNet50\n",
    "from backbones.vgg16 import VGG16\n",
    "from backbones.vgg19 import VGG19\n",
    "from backbones.mobilenetv3small import MobileNetV3Small\n",
    "import utils.tensor as tensor_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c331a1-34bc-4d50-8331-fef78a0ad386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    return input_batch\n",
    "\n",
    "base_dir = \"images/flower_objects\"\n",
    "paths = os.listdir(base_dir)\n",
    "paths = [f for f in paths if os.path.isfile(f\"{base_dir}/{f}\")]\n",
    "input_batches = torch.cat([preprocess_image(base_dir + \"/\" + path) for path in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f31cd-ecf6-47ca-9381-f5526f8827de",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa926164-dd34-47cd-84aa-f186e6cf0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "layer_num = 4\n",
    "n_components=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79edfa-6578-45c7-be2d-9ce192d3f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model activations for each image\n",
    "activations = model.get_features(input_batches, layer_num)\n",
    "batch_size, channels, h, w = activations.shape\n",
    "print(\"ACT\", activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9c374-0515-4f9a-8b76-c4f8332b2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13728a98-333d-42fe-909d-8535c0c1e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "tsne_embeddings = tsne.fit_transform(activations.reshape(activations.shape[0], -1))\n",
    "activations.reshape(activations.shape[0], -1).shape\n",
    "plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1701eed3-d217-4030-add9-c34de8b95374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the activation tensor\n",
    "reshaped_activations = torch.permute(activations, (1, 0, 2, 3))\n",
    "print(\"RE_ACT\", reshaped_activations.shape)\n",
    "# Eliminate NaN values\n",
    "reshaped_activations[np.isnan(reshaped_activations)] = 0\n",
    "reshaped_activations = reshaped_activations.reshape(reshaped_activations.shape[0], -1)\n",
    "print(\"RE_ACT2\", reshaped_activations.shape)\n",
    "offset = reshaped_activations.min(axis=1)[0].reshape(-1, 1)\n",
    "print(\"OFFSET\", offset, offset.shape)\n",
    "reshaped_activations = reshaped_activations - offset\n",
    "\n",
    "model_nmf = NMF(n_components=n_components, init='random', random_state=0)\n",
    "W = model_nmf.fit_transform(reshaped_activations)\n",
    "H = model_nmf.components_\n",
    "print(\"W\", W.shape, \"offset\", offset.shape)\n",
    "concepts = W + offset.detach().cpu().numpy()\n",
    "explanations = H.reshape(n_components, batch_size, h, w)\n",
    "explanations = explanations.transpose((1, 0, 2, 3))\n",
    "concepts.shape, explanations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8ef8c-dcb9-464f-9f9a-50b3cdf7b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, channels, h, w = explanations.shape\n",
    "explanations_reshaped = explanations.reshape(batch_size, channels, -1)\n",
    "logits = torch.nn.functional.softmax(torch.tensor(explanations_reshaped), dim=2)\n",
    "logits = logits.reshape(batch_size, channels, h, w).detach().cpu().numpy()\n",
    "print(logits.shape)\n",
    "\n",
    "fig, ax = plt.subplots(n_components, 2)\n",
    "\n",
    "for i in range(n_components):\n",
    "    ax[i, 0].imshow(logits[0, i])\n",
    "    ax[i, 1].imshow(logits[0, 0] > logits[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b206ba5e-f0a8-482e-b40d-123357c30dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_height = feature_maps[0].shape[1]\n",
    "feature_map_size = feature_map_height**2\n",
    "feature_map_dim = feature_maps[0].shape[3]\n",
    "\n",
    "print(\"feature_map_height\", feature_map_height, \"feature_map_dim\", feature_map_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e95c5f1-fed9-491d-b119-a3bfbd3e4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarrays = [f.detach().cpu().numpy().reshape(feature_map_size, feature_map_dim) for f in feature_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71f001-b417-41d1-828b-faf906795440",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.concatenate(ndarrays)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3491ca-7aea-464d-beda-2c4817b9f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=2, max_iter=200)\n",
    "nmf.fit(d)\n",
    "nmf_features = nmf.transform(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa72900-fd6a-42e4-a920-5ed2a7b2f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa36a4f-9bb8-4a84-be52-b160c3e0dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.components_.shape, nmf.reconstruction_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2bfce7-892f-4a86-ab3e-f2a1e0b50e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist1 = np.linalg.norm(d - nmf.components_[0], axis=1)\n",
    "dist2 = np.linalg.norm(d - nmf.components_[1], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0e6dd-d42f-45aa-a1d0-33bb97c81f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = (dist1 < dist2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37185bb-0b4a-4e45-af34-260d8b514e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,8))\n",
    "ax[0].imshow(np.asarray(Image.open(paths[i])))\n",
    "ax[1].imshow(clusters[i*feature_map_size:(i+1)*feature_map_size].reshape(feature_map_height, feature_map_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cda07c-afea-4c6a-a52f-a6900bf6b064",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "embeddings = tsne.fit_transform(nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a79ebb-7dae-47b4-9cf6-68890c68702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embeddings[:, 0], embeddings[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465a4d3-5408-420b-83e5-e9b14573e9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
